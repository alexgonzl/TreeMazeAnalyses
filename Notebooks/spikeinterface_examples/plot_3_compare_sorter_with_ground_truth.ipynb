{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompare spike sorting output with ground-truth recordings\n=========================================================\n\nSimulated recordings or paired pipette and extracellular recordings can\nbe used to validate spike sorting algorithms.\n\nFor comparing to ground-truth data, the\n:code:`compare_sorter_to_ground_truth(gt_sorting, tested_sorting)` function\ncan be used. In this recording, we have ground-truth information for all\nunits, so we can set :code:`exhaustive_gt` to :code:`True`.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport spikeinterface.extractors as se\nimport spikeinterface.sorters as sorters\nimport spikeinterface.comparison as sc\nimport spikeinterface.widgets as sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recording, sorting_true = se.example_datasets.toy_example(num_channels=4, duration=10, seed=0)\n\nsorting_MS4 = sorters.run_mountainsort4(recording)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cmp_gt_MS4 = sc.compare_sorter_to_ground_truth(sorting_true, sorting_MS4, exhaustive_gt=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To have an overview of the match we can use the unordered agreement matrix\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sw.plot_agreement_matrix(cmp_gt_MS4, ordered=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or ordered\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sw.plot_agreement_matrix(cmp_gt_MS4, ordered=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function first matches the ground-truth and spike sorted units, and\nthen it computes several performance metrics.\n\nOnce the spike trains are matched, each spike is labelled as: \n\n- true positive (tp): spike found both in :code:`gt_sorting` and :code:`tested_sorting`\n- false negative (fn): spike found in :code:`gt_sorting`, but not in :code:`tested_sorting` \n- false positive (fp): spike found in :code:`tested_sorting`, but not in :code:`gt_sorting` \n\nFrom the counts of these labels the following performance measures are\ncomputed:\n\n-  accuracy: #tp / (#tp+ #fn + #fp)\n-  recall: #tp / (#tp + #fn)\n-  precision: #tp / (#tp + #fn)\n-  miss rate: #fn / (#tp + #fn1)\n-  false discovery rate: #fp / (#tp + #fp)\n\nThe :code:`get_performance` method a pandas dataframe (or a dictionary if\n:code:`output='dict'`) with the comparison metrics. By default, these are\ncalculated for each spike train of :code:`sorting1:code:`, the results can be\npooles by average (average of the metrics) and by sum (all counts are\nsummed and the metrics are computed then).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "perf = cmp_gt_MS4.get_performance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets use seaborn swarm plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig1, ax1 = plt.subplots()\nperf2 = pd.melt(perf, var_name='measurement')\nax1 = sns.swarmplot(data=perf2, x='measurement', y='value', ax=ax1)\nax1.set_xticklabels(labels=ax1.get_xticklabels(), rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The confusion matrix is also a good summary of the score as it has\n\u00a0the same shape as agreement matrix, but it contains an extra column for FN\n and an extra row for FP\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sw.plot_confusion_matrix(cmp_gt_MS4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can query the well and bad detected units. By default, the threshold\non accuracy is 0.95.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cmp_gt_MS4.get_well_detected_units()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cmp_gt_MS4.get_false_positive_units()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cmp_gt_MS4.get_redundant_units()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets do the same for klusta\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sorting_KL = sorters.run_klusta(recording)\ncmp_gt_KL = sc.compare_sorter_to_ground_truth(sorting_true, sorting_KL, exhaustive_gt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "perf = cmp_gt_KL.get_performance()\n\nprint(perf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets use seaborn swarm plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig2, ax2 = plt.subplots()\nperf2 = pd.melt(perf, var_name='measurement')\nax2 = sns.swarmplot(data=perf2, x='measurement', y='value', ax=ax2)\nax2.set_xticklabels(labels=ax2.get_xticklabels(), rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(cmp_gt_KL.get_well_detected_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(cmp_gt_KL.get_false_positive_units())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(cmp_gt_KL.get_redundant_units())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}